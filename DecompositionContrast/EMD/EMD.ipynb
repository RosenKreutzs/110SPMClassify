{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 数据准备",
   "id": "3a7a785b5dc4fe64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T12:59:16.619918Z",
     "start_time": "2024-08-10T12:59:10.790237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os  \n",
    "import torch  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_dir = '../../DataFiles/ODS/strain'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_data0 = []  \n",
    "y_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_data0.append(serie)\n",
    "        y_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_data0[i] = df.astype(float) \n",
    "\n",
    "# 初始化X_data1来存储结果  \n",
    "X_data1 = []  \n",
    "  \n",
    "# 遍历X_data0中的每个Series  \n",
    "for series in X_data0:  \n",
    "    # 计算步长（由于重叠率为50%，步长为序列长度的一半）  \n",
    "    step_size = 1024  # 因为2048的一半是1024，且我们想要50%的重叠  \n",
    "    # 初始化一个空的list来存储子序列  \n",
    "    subsequences = []  \n",
    "    # 使用range和步长来生成子序列  \n",
    "    for i in range(0, len(series) - 2048+ 1, step_size):  \n",
    "        # 确保切片是一维的，并转换为Series（虽然这里切片已经是Series）  \n",
    "        subsequence = series.iloc[i:i+2048]  \n",
    "        subsequences.append(subsequence) \n",
    "    X_data1.append(subsequences)  \n",
    "print((type(X_data1),len(X_data1),len(X_data1[0])))\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from keras.utils import to_categorical\n",
    "import time  \n",
    "from keras.callbacks import Callback  \n",
    "import torch \n",
    "\n",
    "# 假设 X_data1 已经定义好了  \n",
    "all_data = []  \n",
    "all_labels = []  \n",
    "  \n",
    "for sublist in X_data1:  \n",
    "    for series in sublist:  \n",
    "        # 假设每个series是pandas Series  \n",
    "        all_data.append(series.values)  \n",
    "        all_labels.append(series.name)  \n",
    "  \n",
    "# 将数据转换为numpy数组  \n",
    "data_array = np.array(all_data)  \n",
    "# 将标签转换为编码  \n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "labels_encoded = label_encoder.fit_transform(all_labels)  \n",
    "  \n",
    "# 如果需要one-hot编码  \n",
    "labels_one_hot = to_categorical(labels_encoded)  \n",
    "  \n",
    "# 这里你可能需要reshape data_array 以符合LSTM的输入要求  \n",
    "# LSTM通常要求输入形状为 (samples, time_steps, features)  \n",
    "# 假设每个series的长度相同，或者你可以填充/截断它们以具有相同的长度  \n",
    "# time_steps = data_array.shape[1]  # 假设所有series长度相同  \n",
    "# data_array = data_array.reshape(-1, time_steps, 1)  # 增加一个维度以匹配LSTM的输入要求\n",
    "\n",
    "# 分割数据集  \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data_array, labels_one_hot, test_size=0.3, random_state=42)  \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print((type(X_train),X_train.shape,type(y_train),y_train.shape))\n",
    "X_train_first_12 = X_train[:12]  "
   ],
   "id": "1144027e7e8d02a6",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# EMD的实现和效果展示\n",
    "- 我的个人理解：[EMD](https://github.com/RosenKreutzs/ClassifyBearing/blob/master/LSTM/EXPLAINATION_EMD.md)；"
   ],
   "id": "5eea7b9bc2b750ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## step1:对原始信号进行EMD操作，获得IMF组；",
   "id": "3661540b4405ab75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T13:07:59.119517Z",
     "start_time": "2024-08-10T13:07:35.592685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess  \n",
    "  \n",
    "# 执行shell命令并等待完成  \n",
    "result = subprocess.run(['pip', 'install','EMD-signal'], capture_output=True, text=True) \n",
    "import numpy as np  \n",
    "from PyEMD import EMD  \n",
    "import time     \n",
    "  \n",
    "# 初始化一个空列表来存储重构后的信号  \n",
    "reconstructed_signals = [] \n",
    "IMFs_list=[]\n",
    "start_time = time.time() \n",
    "# 对每条序列进行EMD分解和重构  \n",
    "for signal in X_train_first_12:  \n",
    "    # 创建EMD对象并传入信号  \n",
    "    emd = EMD()  \n",
    "    IMFs = emd.emd(signal)  \n",
    "    IMFs_list.append(IMFs)\n",
    "    residual = signal - np.sum(IMFs, axis=0)\n",
    "    # 重构信号：将所有本征模态函数（IMF）和残差相加  \n",
    "    reconstructed_signal = np.sum(IMFs, axis=0) + residual  \n",
    "      \n",
    "    # 将重构后的信号添加到列表中  \n",
    "    reconstructed_signals.append(reconstructed_signal)  \n",
    "end_time = time.time()\n",
    "\n",
    "# 将重构后的信号列表转换为numpy数组（如果需要的话）  \n",
    "reconstructed_signals_array = np.array(reconstructed_signals)  \n",
    "\n",
    "# 你可以选择检查第一条重构信号与原始信号之间的差异\n",
    "# 两个向量（或数组）之间的欧几里得距离（或L2范数）\n",
    "L2_mean=0\n",
    "nmse_mean=0\n",
    "\n",
    "for i in range(12):\n",
    "    #欧几里得距离（或L2范数）\n",
    "    L2_mean=L2_mean+np.linalg.norm(X_train_first_12[i]- reconstructed_signals_array[i])\n",
    "    \n",
    "    #归一化均方误差（NMSE）\n",
    "        # 计算MSE  \n",
    "    mse = np.mean((X_train_first_12[i] - reconstructed_signals_array[i]) ** 2)  \n",
    "        # 计算原始信号的能量  \n",
    "    original_energy = np.sum(X_train_first_12[i] ** 2) \n",
    "        # 计算NMSE  \n",
    "    nmse_mean = nmse_mean + mse / original_energy  \n",
    "\n",
    "L2_mean=L2_mean/(i+1)\n",
    "nmse_mean=nmse_mean/(i+1)\n",
    "time_mean=(end_time - start_time)/(i+1)\n",
    "print(f\"time_mean:{time_mean};L2_mean:{L2_mean};nmse_mean:{nmse_mean}\")\n"
   ],
   "id": "6f932613bfbc8c25",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## step2:显示IMF组和原始信号和重构信号；\n",
    "- 每个IMF都代表了原始信号的某种固有振动模式信息；\n",
    "- IMF包含的信息可通过[筛选](../../ModelsContrast/110spmemdlstmvibration.ipynb)后，以达到去噪的效果；之后再重构；"
   ],
   "id": "27904607aef96935"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T13:23:38.881472Z",
     "start_time": "2024-08-10T13:23:32.385683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "    # 原始信号图\n",
    "plt.plot(X_train_first_12[0])  \n",
    "plt.title(\"Original Signal\")\n",
    "plt.xlabel('Time(s)')  # 设置x轴标签  \n",
    "plt.ylabel('Value')  # 设置y轴标签  \n",
    "plt.show()\n",
    "\n",
    "    #IMF组图\n",
    "# 创建一个包含9个子图的图形，每个子图占据1行1列  \n",
    "fig, axs = plt.subplots(9, 1, figsize=(10, 20))  # 调整figsize以适合你的需要  \n",
    "  \n",
    "# 遍历每个子图和对应的数据  \n",
    "for i, ax in enumerate(axs):  \n",
    "    ax.plot(IMFs_list[0][i])  # 绘制第i个一维序列  \n",
    "    ax.set_title(f'IMF {i+1}')  # 设置子图的标题  \n",
    "    ax.set_xlabel('Time(s)')  # 设置x轴标签  \n",
    "    ax.set_ylabel('Value')  # 设置y轴标签  \n",
    "  \n",
    "# 调整子图之间的间距  \n",
    "plt.tight_layout()  \n",
    "  \n",
    "# 显示图形  \n",
    "plt.show()\n",
    "\n",
    "    # 重构信号图\n",
    "plt.plot(reconstructed_signals[0])  \n",
    "plt.title(\"Reconstructed Signal\")\n",
    "plt.xlabel('Time(s)')  # 设置x轴标签  \n",
    "plt.ylabel('Value')  # 设置y轴标签  \n",
    "plt.show()"
   ],
   "id": "e3f65a9010d3ccaf",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "79c65f468fc11d8",
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5319136,
     "sourceId": 8838704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10059.379349,
   "end_time": "2024-07-11T10:30:02.807899",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-11T07:42:23.428550",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
