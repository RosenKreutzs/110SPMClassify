{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d01ada",
   "metadata": {
    "papermill": {
     "duration": 0.004152,
     "end_time": "2024-07-11T07:42:26.160586",
     "exception": false,
     "start_time": "2024-07-11T07:42:26.156434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52ff207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:42:26.170564Z",
     "iopub.status.busy": "2024-07-11T07:42:26.170196Z",
     "iopub.status.idle": "2024-07-11T07:42:41.196070Z",
     "shell.execute_reply": "2024-07-11T07:42:41.195109Z"
    },
    "papermill": {
     "duration": 15.03416,
     "end_time": "2024-07-11T07:42:41.198668",
     "exception": false,
     "start_time": "2024-07-11T07:42:26.164508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import os  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_vibration_dir = '../DataFiles/ODS/vibration'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_vibration_data0 = []  \n",
    "y_vibration_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_vibration_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_vibration_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_vibration_data0.append(serie)\n",
    "        y_vibration_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_vibration_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_vibration_data0[i] = df.astype(float) \n",
    "import os  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_pressure_dir = '/kaggle/input/110spm/110SPM/pressure'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_pressure_data0 = []  \n",
    "y_pressure_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_pressure_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_pressure_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_pressure_data0.append(serie)\n",
    "        y_pressure_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_pressure_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_pressure_data0[i] = df.astype(float) \n",
    "import os  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_strain_dir = '/kaggle/input/110spm/110SPM/strain'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_strain_data0 = []  \n",
    "y_strain_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_strain_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_strain_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_strain_data0.append(serie)\n",
    "        y_strain_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_strain_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_strain_data0[i] = df.astype(float) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edec3cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:42:41.208906Z",
     "iopub.status.busy": "2024-07-11T07:42:41.208502Z",
     "iopub.status.idle": "2024-07-11T07:44:55.337640Z",
     "shell.execute_reply": "2024-07-11T07:44:55.336727Z"
    },
    "papermill": {
     "duration": 134.141365,
     "end_time": "2024-07-11T07:44:55.344444",
     "exception": false,
     "start_time": "2024-07-11T07:42:41.203079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "X_data1=[]\n",
    "y_data1=[]\n",
    "for vibration_serie in X_vibration_data0:\n",
    "    series=[]\n",
    "    series.append(vibration_serie)\n",
    "    for strain_serie in X_strain_data0:\n",
    "        if vibration_serie.name[0:3] == strain_serie.name[0:3]:\n",
    "            series.append(strain_serie)\n",
    "    for pressure_serie in X_pressure_data0:\n",
    "        if vibration_serie.name[0:3] == pressure_serie.name[0:3]:\n",
    "            series.append(pressure_serie)\n",
    "    df=pd.DataFrame(series)\n",
    "    X_data1.append(df)\n",
    "    y_data1.append(vibration_serie.name[0:3])\n",
    "len(X_data1),y_data1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a11cd06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:44:55.354538Z",
     "iopub.status.busy": "2024-07-11T07:44:55.353836Z",
     "iopub.status.idle": "2024-07-11T07:44:55.360749Z",
     "shell.execute_reply": "2024-07-11T07:44:55.359711Z"
    },
    "papermill": {
     "duration": 0.014335,
     "end_time": "2024-07-11T07:44:55.362852",
     "exception": false,
     "start_time": "2024-07-11T07:44:55.348517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "X_data1[0].shape,y_data1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0de0c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:44:55.373776Z",
     "iopub.status.busy": "2024-07-11T07:44:55.373021Z",
     "iopub.status.idle": "2024-07-11T07:45:16.720078Z",
     "shell.execute_reply": "2024-07-11T07:45:16.719021Z"
    },
    "papermill": {
     "duration": 21.355138,
     "end_time": "2024-07-11T07:45:16.722532",
     "exception": false,
     "start_time": "2024-07-11T07:44:55.367394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "  \n",
    "def split_dataframe(df, window_size=512, step_size=256, num_cols=3):  \n",
    "    # 确保只取前num_cols列  \n",
    "    df = df.iloc[:num_cols, :]  \n",
    "    # 计算可以分割成多少个窗口  \n",
    "    num_windows = (df.shape[1] - window_size) // step_size + 1  \n",
    "    # 存储分割后的DataFrame块  \n",
    "    windows = []  \n",
    "    # 应用滑动窗口  \n",
    "    for i in range(0, df.shape[1] - window_size + 1, step_size):  \n",
    "        window = df.iloc[:num_cols,i:i+window_size]  \n",
    "        windows.append(window)  \n",
    "      \n",
    "    return windows  \n",
    "  \n",
    "# 初始化y_data2  \n",
    "y_data2 = []  \n",
    "X_data2=[] \n",
    "# 遍历X_data1和y_data1  \n",
    "for df, label in zip(X_data1, y_data1):  \n",
    "    # 分割DataFrame  \n",
    "    windows = split_dataframe(df)  \n",
    "    # 为每个窗口分配相同的标签  \n",
    "    for window in windows: \n",
    "        df_window=window.T\n",
    "        y_data2.append(label)  \n",
    "        X_data2.append(df_window)\n",
    "X_data2[0].shape,len(X_data2),len(y_data2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6910eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:45:16.733385Z",
     "iopub.status.busy": "2024-07-11T07:45:16.732639Z",
     "iopub.status.idle": "2024-07-11T07:45:29.929538Z",
     "shell.execute_reply": "2024-07-11T07:45:29.928543Z"
    },
    "papermill": {
     "duration": 13.204821,
     "end_time": "2024-07-11T07:45:29.931944",
     "exception": false,
     "start_time": "2024-07-11T07:45:16.727123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from keras.utils import to_categorical\n",
    "# 将标签转换为编码  \n",
    "all_labels=y_data2\n",
    "label_encoder = LabelEncoder()  \n",
    "labels_encoded = label_encoder.fit_transform(all_labels)  \n",
    "  \n",
    "# 如果需要one-hot编码  \n",
    "labels_one_hot = to_categorical(labels_encoded)\n",
    "y_data3=labels_one_hot\n",
    "y_data3[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e715c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:45:29.943155Z",
     "iopub.status.busy": "2024-07-11T07:45:29.942505Z",
     "iopub.status.idle": "2024-07-11T07:45:33.207320Z",
     "shell.execute_reply": "2024-07-11T07:45:33.206214Z"
    },
    "papermill": {
     "duration": 3.27331,
     "end_time": "2024-07-11T07:45:33.209902",
     "exception": false,
     "start_time": "2024-07-11T07:45:29.936592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import random  \n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "  \n",
    "# 假设X_data2和y_data2已经定义好了  \n",
    "X_data3=np.array(X_data2)  \n",
    "# 整合数据  \n",
    "data = list(zip(X_data3, y_data3))  \n",
    "  \n",
    "# 打乱数据  \n",
    "random.shuffle(data)  \n",
    "  \n",
    "# 分离X和y  \n",
    "X_data3, y_data3 = zip(*data)  \n",
    "# 首次分割成训练集和临时集（这里假设80%训练，剩下的20%用于后续分割）  \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_data3, y_data3, test_size=0.2, random_state=42)  \n",
    "  \n",
    "# 对临时集进行第二次分割，得到测试集和验证集（这里假设测试集和验证集各占临时集的一半）  \n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  \n",
    "X_train = np.array(X_train)  \n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)  \n",
    "y_test = np.array(y_test)\n",
    "X_val = np.array(X_val)  \n",
    "y_val = np.array(y_val)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "90645f91",
   "metadata": {
    "papermill": {
     "duration": 0.00436,
     "end_time": "2024-07-11T07:45:33.218969",
     "exception": false,
     "start_time": "2024-07-11T07:45:33.214609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca45589e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:45:33.230112Z",
     "iopub.status.busy": "2024-07-11T07:45:33.229356Z",
     "iopub.status.idle": "2024-07-11T10:28:30.784602Z",
     "shell.execute_reply": "2024-07-11T10:28:30.783478Z"
    },
    "papermill": {
     "duration": 9777.563578,
     "end_time": "2024-07-11T10:28:30.787067",
     "exception": false,
     "start_time": "2024-07-11T07:45:33.223489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten  \n",
    "   \n",
    "# 构建模型  \n",
    "model = Sequential([  \n",
    "    # CNN 层（可能不是必需的，但可以尝试）  \n",
    "    Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(512, 3)),  \n",
    "    MaxPooling1D(pool_size=2),  \n",
    "    # 将 CNN 的输出展平，以便可以传递给 LSTM  \n",
    "    Flatten(),  \n",
    "    # 注意：这里我们实际上可以跳过了 LSTM，因为 Flatten() 破坏了时间序列结构  \n",
    "    # 但如果您想要保留 LSTM，您需要重新考虑如何使用 CNN  \n",
    "    # LSTM 层（如果需要的话）  \n",
    "    # LSTM(64, return_sequences=False),  \n",
    "    # 由于我们跳过了 LSTM，我们直接添加全连接层  \n",
    "    Dense(64, activation='relu'),  \n",
    "    Dense(12, activation='softmax')  \n",
    "])  \n",
    "  \n",
    "# 注意：上面的模型没有 LSTM 层，因为 Flatten() 破坏了时间序列结构  \n",
    "# 如果您想要使用 LSTM，您可能需要重新设计 CNN 部分，或者不使用 Flatten()  \n",
    "# 并使用 TimeDistributed 包装器（但在这里可能不适用，因为特征数太少）  \n",
    "  \n",
    "# 编译模型  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "  \n",
    "# 训练模型  \n",
    "history=model.fit(X_train, y_train, epochs=1000,batch_size=32,validation_data=(X_val, y_val))\n",
    "model.save(\"/kaggle/working/3EMD_CNN_model.h5\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1e1f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T10:28:55.373000Z",
     "iopub.status.busy": "2024-07-11T10:28:55.372580Z",
     "iopub.status.idle": "2024-07-11T10:28:55.909839Z",
     "shell.execute_reply": "2024-07-11T10:28:55.908835Z"
    },
    "papermill": {
     "duration": 12.730956,
     "end_time": "2024-07-11T10:28:55.911943",
     "exception": false,
     "start_time": "2024-07-11T10:28:43.180987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# 绘制训练loss和验证loss  \n",
    "plt.plot(history.history['loss'], label='train')  \n",
    "plt.plot(history.history['val_loss'], label='val')  \n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('Model loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.show()  \n",
    "  \n",
    "# 绘制训练accuracy和验证accuracy  \n",
    "plt.plot(history.history['accuracy'], label='train')  \n",
    "plt.plot(history.history['val_accuracy'], label='val')  \n",
    "plt.legend(loc='lower right')  \n",
    "plt.title('Model accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylim(ymin=0, ymax=1)  # 设置y轴的范围为0到1  \n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e715ef09",
   "metadata": {
    "papermill": {
     "duration": 12.381344,
     "end_time": "2024-07-11T10:29:20.612164",
     "exception": false,
     "start_time": "2024-07-11T10:29:08.230820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ec3d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T10:29:45.117852Z",
     "iopub.status.busy": "2024-07-11T10:29:45.117106Z",
     "iopub.status.idle": "2024-07-11T10:29:47.677337Z",
     "shell.execute_reply": "2024-07-11T10:29:47.676234Z"
    },
    "papermill": {
     "duration": 14.681814,
     "end_time": "2024-07-11T10:29:47.680060",
     "exception": false,
     "start_time": "2024-07-11T10:29:32.998246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.models import load_model  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "  \n",
    "# # 加载模型  \n",
    "# model = load_model(\"/kaggle/input/110spmlstm/keras/110spmlstm/1/model.h5\")  \n",
    "  \n",
    "# 假设X_test和y_test是你的测试数据和真实标签（整数索引）  \n",
    "# 这里需要你已经有了这些变量  \n",
    "  \n",
    "# 预测测试集  \n",
    "y_pred = model.predict(X_test)  \n",
    "# 对于多分类问题，使用argmax获取预测类别索引  \n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  \n",
    "   \n",
    "# 计算混淆矩阵  \n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)  # 确保y_test也是索引形式  \n",
    "  \n",
    "# 获取所有唯一标签的列表，这些标签将对应于整数编码的索引  \n",
    "class_names = label_encoder.classes_  \n",
    "\n",
    "# 绘制混淆矩阵  \n",
    "plt.figure(figsize=(12, 10))  \n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)  \n",
    "plt.ylabel('Actual')  \n",
    "plt.xlabel('Predicted')  \n",
    "plt.title('Confusion Matrix')  \n",
    "plt.show()\n",
    "\n",
    "# 评估模型  \n",
    "loss, accuracy = model.evaluate(X_test, y_test)  \n",
    "print(f'Test loss: {loss:.4f}')  \n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5319136,
     "sourceId": 8838704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10059.379349,
   "end_time": "2024-07-11T10:30:02.807899",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-11T07:42:23.428550",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
