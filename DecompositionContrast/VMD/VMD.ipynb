{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 数据准备",
   "id": "3a7a785b5dc4fe64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:27:25.490828Z",
     "start_time": "2024-08-10T14:26:49.987989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os  \n",
    "import torch  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_dir = '../../DataFiles/ODS/strain'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_data0 = []  \n",
    "y_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_data0.append(serie)\n",
    "        y_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_data0[i] = df.astype(float) \n",
    "\n",
    "# 初始化X_data1来存储结果  \n",
    "X_data1 = []  \n",
    "  \n",
    "# 遍历X_data0中的每个Series  \n",
    "for series in X_data0:  \n",
    "    # 计算步长（由于重叠率为50%，步长为序列长度的一半）  \n",
    "    step_size = 1024  # 因为2048的一半是1024，且我们想要50%的重叠  \n",
    "    # 初始化一个空的list来存储子序列  \n",
    "    subsequences = []  \n",
    "    # 使用range和步长来生成子序列  \n",
    "    for i in range(0, len(series) - 2048+ 1, step_size):  \n",
    "        # 确保切片是一维的，并转换为Series（虽然这里切片已经是Series）  \n",
    "        subsequence = series.iloc[i:i+2048]  \n",
    "        subsequences.append(subsequence) \n",
    "    X_data1.append(subsequences)  \n",
    "print((type(X_data1),len(X_data1),len(X_data1[0])))\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from keras.utils import to_categorical\n",
    "import time  \n",
    "from keras.callbacks import Callback  \n",
    "import torch \n",
    "\n",
    "# 假设 X_data1 已经定义好了  \n",
    "all_data = []  \n",
    "all_labels = []  \n",
    "  \n",
    "for sublist in X_data1:  \n",
    "    for series in sublist:  \n",
    "        # 假设每个series是pandas Series  \n",
    "        all_data.append(series.values)  \n",
    "        all_labels.append(series.name)  \n",
    "  \n",
    "# 将数据转换为numpy数组  \n",
    "data_array = np.array(all_data)  \n",
    "# 将标签转换为编码  \n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "labels_encoded = label_encoder.fit_transform(all_labels)  \n",
    "  \n",
    "# 如果需要one-hot编码  \n",
    "labels_one_hot = to_categorical(labels_encoded)  \n",
    "  \n",
    "# 这里你可能需要reshape data_array 以符合LSTM的输入要求  \n",
    "# LSTM通常要求输入形状为 (samples, time_steps, features)  \n",
    "# 假设每个series的长度相同，或者你可以填充/截断它们以具有相同的长度  \n",
    "# time_steps = data_array.shape[1]  # 假设所有series长度相同  \n",
    "# data_array = data_array.reshape(-1, time_steps, 1)  # 增加一个维度以匹配LSTM的输入要求\n",
    "\n",
    "# 分割数据集  \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data_array, labels_one_hot, test_size=0.3, random_state=42)  \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print((type(X_train),X_train.shape,type(y_train),y_train.shape))\n",
    "X_train_first_12 = X_train[:12]  "
   ],
   "id": "1144027e7e8d02a6",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# VMD的实现和效果展示\n",
    "- 我的个人理解：[VMD](https://github.com/RosenKreutzs/ClassifyBearing/blob/master/LSTM/EXPLAINATION_VMD.md)；"
   ],
   "id": "5eea7b9bc2b750ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## step1:对原始信号进行VMD操作，获得IMF组；",
   "id": "3661540b4405ab75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T14:28:18.655510Z",
     "start_time": "2024-08-10T14:28:13.401129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from vmdpy import VMD   \n",
    "  \n",
    "# -----测试信号及其参数--start-------------\n",
    "signal=X_train_first_12[0]\n",
    "T = len(signal)\n",
    "fs = 1/T\n",
    "t = np.arange(1,T+1)/T\n",
    " \n",
    "# alpha 惩罚系数；带宽限制经验取值为抽样点长度1.5-2.0倍.\n",
    "# 惩罚系数越小，各IMF分量的带宽越大，过大的带宽会使得某些分量包含其他分量言号;\n",
    "alpha = 1000\n",
    " \n",
    "#噪声容限，一般取 0, 即允许重构后的信号与原始信号有差别。\n",
    "tau = 0 \n",
    "#模态数量  分解模态（IMF）个数\n",
    "K = 5\n",
    " \n",
    "#DC 合成信号若无常量，取值为 0；若含常量，则其取值为 1\n",
    "# DC 若为0则让第一个IMF为直流分量/趋势向量\n",
    "DC = 0 \n",
    "#初始化ω值，当初始化为 1 时，均匀分布产生的随机数\n",
    "# init 指每个IMF的中心频率进行初始化。当初始化为1时，进行均匀初始化。\n",
    "init = 1 \n",
    "#控制误差大小常量，决定精度与迭代次数\n",
    "tol = 1e-7\n",
    "# -----测试信号及其参数--end----------\n",
    " \n",
    "# Apply VMD\n",
    "# 输出U是各个IMF分量，u_hat是各IMF的频谱，omega为各IMF的中心频率\n",
    "u, u_hat, omega= VMD(signal, alpha, tau, K, DC, init, tol)\n"
   ],
   "id": "6f932613bfbc8c25",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## step2:显示IMF组和原始信号和重构信号；\n",
    "- 每个IMF都代表了原始信号的某种固有振动模式信息；\n",
    "- IMF包含的信息可通过筛选(评估IMF与原始信号的相关性)后，以达到去噪的效果；之后再重构；"
   ],
   "id": "27904607aef96935"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#得到中心频率的数值\n",
    "print(omega[-1])\n",
    "# Plot the original signal and decomposed modes\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(K+1, 1, 1)\n",
    "plt.plot(t, signal, 'r')\n",
    "plt.title(\"原始信号\")\n",
    "for num in range(K):\n",
    "    plt.subplot(K+1, 1, num+2)\n",
    "    plt.plot(t, u[num,:])\n",
    "    plt.title(\"IMF \"+str(num+1))\n",
    " \n",
    "plt.show()"
   ],
   "id": "e3f65a9010d3ccaf",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "79c65f468fc11d8",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5319136,
     "sourceId": 8838704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10059.379349,
   "end_time": "2024-07-11T10:30:02.807899",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-11T07:42:23.428550",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
