{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e141c21",
   "metadata": {
    "papermill": {
     "duration": 0.004658,
     "end_time": "2024-07-09T03:47:24.943311",
     "exception": false,
     "start_time": "2024-07-09T03:47:24.938653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3390802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:47:24.953642Z",
     "iopub.status.busy": "2024-07-09T03:47:24.953213Z",
     "iopub.status.idle": "2024-07-09T03:47:34.852861Z",
     "shell.execute_reply": "2024-07-09T03:47:34.851748Z"
    },
    "papermill": {
     "duration": 9.908,
     "end_time": "2024-07-09T03:47:34.855589",
     "exception": false,
     "start_time": "2024-07-09T03:47:24.947589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import os  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_dir = '../DataFiles/ODS/pressure'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_data0 = []  \n",
    "y_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_data0.append(serie)\n",
    "        y_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_data0[i] = df.astype(float) \n",
    "\n",
    "# 初始化X_data1来存储结果  \n",
    "X_data1 = []  \n",
    "  \n",
    "# 遍历X_data0中的每个Series  \n",
    "for series in X_data0:  \n",
    "    # 计算步长（由于重叠率为50%，步长为序列长度的一半）  \n",
    "    step_size = 256  # 因为512的一半是256，且我们想要50%的重叠  \n",
    "    # 初始化一个空的list来存储子序列  \n",
    "    subsequences = []  \n",
    "    # 使用range和步长来生成子序列  \n",
    "    for i in range(0, len(series) - 512 + 1, step_size):  \n",
    "        # 确保切片是一维的，并转换为Series（虽然这里切片已经是Series）  \n",
    "        subsequence = series.iloc[i:i+512]  \n",
    "        subsequences.append(subsequence) \n",
    "    X_data1.append(subsequences)  \n",
    "type(X_data1),len(X_data1),len(X_data1[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3502e8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:47:34.866610Z",
     "iopub.status.busy": "2024-07-09T03:47:34.866097Z",
     "iopub.status.idle": "2024-07-09T05:18:31.713260Z",
     "shell.execute_reply": "2024-07-09T05:18:31.711681Z"
    },
    "papermill": {
     "duration": 5456.867433,
     "end_time": "2024-07-09T05:18:31.727608",
     "exception": false,
     "start_time": "2024-07-09T03:47:34.860175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import subprocess  \n",
    "# 使用subprocess.run()执行shell命令  \n",
    "result = subprocess.run(['pip', 'install','EMD-signal'], capture_output=True, text=True)\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from PyEMD import EMD  #pip install EMD-signal\n",
    "import matplotlib.pyplot as plt \n",
    "X_data2=[]\n",
    "for sublist in X_data1:  \n",
    "    X_data2_temp=[]\n",
    "    for series0 in sublist: \n",
    "        X_EMD_test=series0.values\n",
    "        emd = EMD()\n",
    "        IMFs = emd.emd(X_EMD_test)  \n",
    "        # 计算残差（原始信号减去所有IMF之和）  \n",
    "        residual = X_EMD_test - np.sum(IMFs, axis=0)  \n",
    "        # 计算相关性和方差贡献率  \n",
    "        x=X_EMD_test\n",
    "        N = len(x)  \n",
    "        rho_xy = []  \n",
    "        mesb = []  \n",
    "        for y_i in IMFs:  \n",
    "            # 计算均值  \n",
    "            x_mean, y_mean = np.mean(x), np.mean(y_i)  \n",
    "            # 计算相关性  \n",
    "            cov_xy = np.sum((x - x_mean) * (y_i - y_mean))  \n",
    "            var_x, var_y = np.sum((x - x_mean)**2), np.sum((y_i - y_mean)**2)  \n",
    "            rho_xy_i = cov_xy / (np.sqrt(var_x) * np.sqrt(var_y))  \n",
    "            rho_xy.append(rho_xy_i)  \n",
    "      \n",
    "            # 计算方差贡献率  \n",
    "            d_i_squared = np.sum((y_i - y_mean)**2) / N  \n",
    "            total_variance = sum(np.sum((imf - np.mean(imf))**2) / N for imf in IMFs)  \n",
    "            mesb_i = d_i_squared / total_variance  \n",
    "            mesb.append(mesb_i)  \n",
    "  \n",
    "        # 计算综合评价指标 K  \n",
    "        alpha, beta = 0.2, 0.8  \n",
    "        K = [alpha * rho + beta * mesb for rho, mesb in zip(rho_xy, mesb)]\n",
    "        noise_imfs=[]\n",
    "        non_noise_imfs=[]\n",
    "        # 区分噪音和非噪音\n",
    "        for i in range(len(K)):\n",
    "            if K[i]< 0.1:\n",
    "                noise_imfs.append(IMFs[i])\n",
    "            else:\n",
    "                non_noise_imfs.append(IMFs[i])\n",
    "        # 重构信号  \n",
    "        reconstructed_signal = np.sum(non_noise_imfs, axis=0) + residual\n",
    "        series1=pd.Series(reconstructed_signal)\n",
    "        series1.name=series0.name\n",
    "        X_data2_temp.append(series1)\n",
    "    X_data2.append(X_data2_temp)\n",
    "len(X_data2),len(X_data2[0]),len(X_data2[0][0]),type(X_data2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f53962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T05:18:31.750326Z",
     "iopub.status.busy": "2024-07-09T05:18:31.749184Z",
     "iopub.status.idle": "2024-07-09T05:18:46.409321Z",
     "shell.execute_reply": "2024-07-09T05:18:46.407767Z"
    },
    "papermill": {
     "duration": 14.675768,
     "end_time": "2024-07-09T05:18:46.412887",
     "exception": false,
     "start_time": "2024-07-09T05:18:31.737119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from keras.utils import to_categorical\n",
    "import time  \n",
    "from keras.callbacks import Callback  \n",
    "# 假设 X_data1 已经定义好了  \n",
    "all_data = []  \n",
    "all_labels = []  \n",
    "  \n",
    "for sublist in X_data2:  \n",
    "    for series in sublist:  \n",
    "        # 假设每个series是pandas Series  \n",
    "        all_data.append(series.values)  \n",
    "        all_labels.append(series.name)  \n",
    "  \n",
    "# 将数据转换为numpy数组  \n",
    "data_array = np.array(all_data)  \n",
    "# 将标签转换为编码  \n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "labels_encoded = label_encoder.fit_transform(all_labels)  \n",
    "  \n",
    "# 如果需要one-hot编码  \n",
    "labels_one_hot = to_categorical(labels_encoded)  \n",
    "  \n",
    "# 这里你可能需要reshape data_array 以符合LSTM的输入要求  \n",
    "# LSTM通常要求输入形状为 (samples, time_steps, features)  \n",
    "# 假设每个series的长度相同，或者你可以填充/截断它们以具有相同的长度  \n",
    "time_steps = data_array.shape[1]  # 假设所有series长度相同  \n",
    "data_array = data_array.reshape(-1, time_steps, 1)  # 增加一个维度以匹配LSTM的输入要求\n",
    "\n",
    "# 分割数据集  \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data_array, labels_one_hot, test_size=0.3, random_state=42)  \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c8cb3ac5",
   "metadata": {
    "papermill": {
     "duration": 0.006493,
     "end_time": "2024-07-09T05:18:46.426254",
     "exception": false,
     "start_time": "2024-07-09T05:18:46.419761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdf7040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T05:18:46.442393Z",
     "iopub.status.busy": "2024-07-09T05:18:46.441630Z",
     "iopub.status.idle": "2024-07-09T12:58:46.608181Z",
     "shell.execute_reply": "2024-07-09T12:58:46.607012Z"
    },
    "papermill": {
     "duration": 27600.177979,
     "end_time": "2024-07-09T12:58:46.611021",
     "exception": false,
     "start_time": "2024-07-09T05:18:46.433042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import LSTM, Dense  \n",
    "  \n",
    "model = Sequential()  \n",
    "model.add(LSTM(50, input_shape=(time_steps, 1)))  \n",
    "model.add(Dense(labels_one_hot.shape[1], activation='softmax'))  \n",
    "  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class TimeBasedCheckpoint(Callback):  \n",
    "    def __init__(self, filepath, time_interval_hours=4, verbose=0, save_weights_only=False):  \n",
    "        super(TimeBasedCheckpoint, self).__init__()  \n",
    "        self.filepath = filepath  \n",
    "        self.time_interval_hours = time_interval_hours  \n",
    "        self.verbose = verbose  \n",
    "        self.save_weights_only = save_weights_only  \n",
    "        self.last_save_time = None  \n",
    "  \n",
    "    def on_epoch_begin(self, epoch, logs=None):  \n",
    "        if self.last_save_time is None:  \n",
    "            self.last_save_time = time.time()  \n",
    "            return  \n",
    "  \n",
    "        current_time = time.time()  \n",
    "        elapsed_time = current_time - self.last_save_time  \n",
    "        if elapsed_time / 3600 >= self.time_interval_hours:  \n",
    "            self.save_model(epoch, logs)  \n",
    "            self.last_save_time = current_time  \n",
    "  \n",
    "    def save_model(self, epoch, logs=None):  \n",
    "        filepath = self.filepath.format(epoch=epoch + 1)  # 假设您想将epoch编号包含在文件名中  \n",
    "        if self.save_weights_only:  \n",
    "            self.model.save_weights(filepath, overwrite=True)  \n",
    "        else:  \n",
    "            self.model.save(filepath, overwrite=True)  \n",
    "        if self.verbose > 0:  \n",
    "            print(f'Model saved to {filepath} at epoch {epoch + 1}')  \n",
    "\n",
    "\n",
    "checkpoint = TimeBasedCheckpoint(filepath='/kaggle/working/model.h5', time_interval_hours=4, verbose=1)  \n",
    "history=model.fit(X_train, y_train, epochs=100, batch_size=32 ,callbacks=[checkpoint] ,validation_data=(X_val, y_val))\n",
    "model.save(\"/kaggle/working/EMD_LSTM_model.h5\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fec86b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T12:59:15.108850Z",
     "iopub.status.busy": "2024-07-09T12:59:15.108298Z",
     "iopub.status.idle": "2024-07-09T12:59:15.770649Z",
     "shell.execute_reply": "2024-07-09T12:59:15.769521Z"
    },
    "papermill": {
     "duration": 14.879807,
     "end_time": "2024-07-09T12:59:15.773220",
     "exception": false,
     "start_time": "2024-07-09T12:59:00.893413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# 绘制训练loss和验证loss  \n",
    "plt.plot(history.history['loss'], label='train')  \n",
    "plt.plot(history.history['val_loss'], label='val')  \n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('Model loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.show()  \n",
    "  \n",
    "# 绘制训练accuracy和验证accuracy  \n",
    "plt.plot(history.history['accuracy'], label='train')  \n",
    "plt.plot(history.history['val_accuracy'], label='val')  \n",
    "plt.legend(loc='lower right')  \n",
    "plt.title('Model accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylim(ymin=0, ymax=1)  # 设置y轴的范围为0到1  \n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "efa5708e",
   "metadata": {
    "papermill": {
     "duration": 14.16338,
     "end_time": "2024-07-09T12:59:43.890482",
     "exception": false,
     "start_time": "2024-07-09T12:59:29.727102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52830b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T13:00:11.904484Z",
     "iopub.status.busy": "2024-07-09T13:00:11.904054Z",
     "iopub.status.idle": "2024-07-09T13:00:59.084978Z",
     "shell.execute_reply": "2024-07-09T13:00:59.083605Z"
    },
    "papermill": {
     "duration": 61.335862,
     "end_time": "2024-07-09T13:00:59.087739",
     "exception": false,
     "start_time": "2024-07-09T12:59:57.751877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.models import load_model  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "  \n",
    "# # 加载模型  \n",
    "# model = load_model(\"/kaggle/input/110spmlstm/keras/110spmlstm/1/model.h5\")  \n",
    "  \n",
    "# 假设X_test和y_test是你的测试数据和真实标签（整数索引）  \n",
    "# 这里需要你已经有了这些变量  \n",
    "  \n",
    "# 预测测试集  \n",
    "y_pred = model.predict(X_test)  \n",
    "# 对于多分类问题，使用argmax获取预测类别索引  \n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  \n",
    "   \n",
    "# 计算混淆矩阵  \n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)  # 确保y_test也是索引形式  \n",
    "  \n",
    "# 获取所有唯一标签的列表，这些标签将对应于整数编码的索引  \n",
    "class_names = label_encoder.classes_  \n",
    "\n",
    "# 绘制混淆矩阵  \n",
    "plt.figure(figsize=(12, 10))  \n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)  \n",
    "plt.ylabel('Actual')  \n",
    "plt.xlabel('Predicted')  \n",
    "plt.title('Confusion Matrix')  \n",
    "plt.show()\n",
    "\n",
    "# 评估模型  \n",
    "loss, accuracy = model.evaluate(X_test, y_test)  \n",
    "print(f'Test loss: {loss:.4f}')  \n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337f3ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T13:01:27.418273Z",
     "iopub.status.busy": "2024-07-09T13:01:27.417871Z",
     "iopub.status.idle": "2024-07-09T13:01:50.046230Z",
     "shell.execute_reply": "2024-07-09T13:01:50.045100Z"
    },
    "papermill": {
     "duration": 36.559329,
     "end_time": "2024-07-09T13:01:50.049043",
     "exception": false,
     "start_time": "2024-07-09T13:01:13.489714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from sklearn.metrics import f1_score, classification_report  \n",
    "import numpy as np  \n",
    "  \n",
    "# 假设 X_test 和 y_test 已经是准备好的测试集数据和标签  \n",
    "  \n",
    "# 使用模型进行预测  \n",
    "y_pred_probs = model.predict(X_test)  # 获取预测的概率  \n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)  # 将概率转换为类别标签  \n",
    "  \n",
    "# 注意：如果你的 y_test 是one-hot编码的，你需要先将其转换为类别索引  \n",
    "y_true_classes = np.argmax(y_test, axis=1)  # 假设 y_test 是one-hot编码的  \n",
    "  \n",
    "# 计算F1分数  \n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')  # 使用加权平均来计算多类别的F1分数  \n",
    "print(f'F1 Score: {f1:.4f}')  \n",
    "  \n",
    "# 计算精确率、召回率和F1分数的详细报告  \n",
    "report = classification_report(y_true_classes, y_pred_classes)  \n",
    "print(report)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5319136,
     "sourceId": 8838704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33285.253189,
   "end_time": "2024-07-09T13:02:07.127306",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-09T03:47:21.874117",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
