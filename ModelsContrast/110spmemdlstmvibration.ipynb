{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03feefc0",
   "metadata": {
    "papermill": {
     "duration": 0.003642,
     "end_time": "2024-07-08T15:37:12.049985",
     "exception": false,
     "start_time": "2024-07-08T15:37:12.046343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "id": "02c88877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T15:37:12.058610Z",
     "iopub.status.busy": "2024-07-08T15:37:12.058183Z",
     "iopub.status.idle": "2024-07-08T15:37:19.804449Z",
     "shell.execute_reply": "2024-07-08T15:37:19.803426Z"
    },
    "papermill": {
     "duration": 7.753185,
     "end_time": "2024-07-08T15:37:19.806786",
     "exception": false,
     "start_time": "2024-07-08T15:37:12.053601",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-31T11:38:55.485310Z",
     "start_time": "2024-07-31T11:38:49.052092Z"
    }
   },
   "source": [
    "import os  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_dir = '../DataFiles/ODS/vibration'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_data0 = []  \n",
    "y_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_data0.append(serie)\n",
    "        y_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_data0[i] = df.astype(float) \n",
    "\n",
    "# 初始化X_data1来存储结果  \n",
    "X_data1 = []  \n",
    "  \n",
    "# 遍历X_data0中的每个Series  \n",
    "for series in X_data0:  \n",
    "    # 计算步长（由于重叠率为50%，步长为序列长度的一半）  \n",
    "    step_size = 256  # 因为512的一半是256，且我们想要50%的重叠  \n",
    "    # 初始化一个空的list来存储子序列  \n",
    "    subsequences = []  \n",
    "    # 使用range和步长来生成子序列  \n",
    "    for i in range(0, len(series) - 512 + 1, step_size):  \n",
    "        # 确保切片是一维的，并转换为Series（虽然这里切片已经是Series）  \n",
    "        subsequence = series.iloc[i:i+512]  \n",
    "        subsequences.append(subsequence) \n",
    "    X_data1.append(subsequences)  \n",
    "type(X_data1),len(X_data1),len(X_data1[0])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 3, 3510)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b3c48008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T15:37:19.815890Z",
     "iopub.status.busy": "2024-07-08T15:37:19.814938Z",
     "iopub.status.idle": "2024-07-08T16:26:20.947794Z",
     "shell.execute_reply": "2024-07-08T16:26:20.946630Z"
    },
    "papermill": {
     "duration": 2941.140347,
     "end_time": "2024-07-08T16:26:20.950594",
     "exception": false,
     "start_time": "2024-07-08T15:37:19.810247",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-07-31T11:54:42.412891Z",
     "start_time": "2024-07-31T11:38:59.178593Z"
    }
   },
   "source": [
    "import subprocess  \n",
    "# 使用subprocess.run()执行shell命令  \n",
    "result = subprocess.run(['pip', 'install','EMD-signal'], capture_output=True, text=True)\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from PyEMD import EMD  #pip install EMD-signal\n",
    "import matplotlib.pyplot as plt \n",
    "X_data2=[]\n",
    "for sublist in X_data1:  \n",
    "    X_data2_temp=[]\n",
    "    for series0 in sublist: \n",
    "        X_EMD_test=series0.values\n",
    "        emd = EMD()\n",
    "        IMFs = emd.emd(X_EMD_test)  \n",
    "        # 计算残差（原始信号减去所有IMF之和）  \n",
    "        residual = X_EMD_test - np.sum(IMFs, axis=0)  \n",
    "        # 计算相关性和方差贡献率  \n",
    "        x=X_EMD_test\n",
    "        N = len(x)  \n",
    "        rho_xy = []  \n",
    "        mesb = []  \n",
    "        for y_i in IMFs:  \n",
    "            # 计算均值  \n",
    "            x_mean, y_mean = np.mean(x), np.mean(y_i)  \n",
    "            # 计算相关性  \n",
    "            cov_xy = np.sum((x - x_mean) * (y_i - y_mean))  \n",
    "            var_x, var_y = np.sum((x - x_mean)**2), np.sum((y_i - y_mean)**2)  \n",
    "            rho_xy_i = cov_xy / (np.sqrt(var_x) * np.sqrt(var_y))  \n",
    "            rho_xy.append(rho_xy_i)  \n",
    "      \n",
    "            # 计算方差贡献率  \n",
    "            d_i_squared = np.sum((y_i - y_mean)**2) / N  \n",
    "            total_variance = sum(np.sum((imf - np.mean(imf))**2) / N for imf in IMFs)  \n",
    "            mesb_i = d_i_squared / total_variance  \n",
    "            mesb.append(mesb_i)  \n",
    "  \n",
    "        # 计算综合评价指标 K  \n",
    "        alpha, beta = 0.2, 0.8  \n",
    "        K = [alpha * rho + beta * mesb for rho, mesb in zip(rho_xy, mesb)]\n",
    "        noise_imfs=[]\n",
    "        non_noise_imfs=[]\n",
    "        # 区分噪音和非噪音\n",
    "        for i in range(len(K)):\n",
    "            if K[i]< 0.1:\n",
    "                noise_imfs.append(IMFs[i])\n",
    "            else:\n",
    "                non_noise_imfs.append(IMFs[i])\n",
    "        # 重构信号  \n",
    "        reconstructed_signal = np.sum(non_noise_imfs, axis=0) + residual\n",
    "        series1=pd.Series(reconstructed_signal)\n",
    "        series1.name=series0.name\n",
    "        X_data2_temp.append(series1)\n",
    "    X_data2.append(X_data2_temp)\n",
    "len(X_data2),len(X_data2[0]),len(X_data2[0][0]),type(X_data2)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m X_EMD_test\u001B[38;5;241m=\u001B[39mseries0\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m     13\u001B[0m emd \u001B[38;5;241m=\u001B[39m EMD()\n\u001B[1;32m---> 14\u001B[0m IMFs \u001B[38;5;241m=\u001B[39m \u001B[43memd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43memd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_EMD_test\u001B[49m\u001B[43m)\u001B[49m  \n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# 计算残差（原始信号减去所有IMF之和）  \u001B[39;00m\n\u001B[0;32m     16\u001B[0m residual \u001B[38;5;241m=\u001B[39m X_EMD_test \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39msum(IMFs, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)  \n",
      "File \u001B[1;32m~\\anaconda3\\envs\\110SPMEnv\\lib\\site-packages\\PyEMD\\EMD.py:822\u001B[0m, in \u001B[0;36mEMD.emd\u001B[1;34m(self, S, T, max_imf)\u001B[0m\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDTYPE \u001B[38;5;241m=\u001B[39m S\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m    820\u001B[0m N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(S)\n\u001B[1;32m--> 822\u001B[0m residue \u001B[38;5;241m=\u001B[39m \u001B[43mS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    823\u001B[0m imf \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(S), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDTYPE)\n\u001B[0;32m    824\u001B[0m imf_old \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1742c211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T16:26:20.959765Z",
     "iopub.status.busy": "2024-07-08T16:26:20.959349Z",
     "iopub.status.idle": "2024-07-08T16:26:34.660660Z",
     "shell.execute_reply": "2024-07-08T16:26:34.659586Z"
    },
    "papermill": {
     "duration": 13.708921,
     "end_time": "2024-07-08T16:26:34.663231",
     "exception": false,
     "start_time": "2024-07-08T16:26:20.954310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from keras.utils import to_categorical\n",
    "import time  \n",
    "from keras.callbacks import Callback  \n",
    "# 假设 X_data1 已经定义好了  \n",
    "all_data = []  \n",
    "all_labels = []  \n",
    "  \n",
    "for sublist in X_data2:  \n",
    "    for series in sublist:  \n",
    "        # 假设每个series是pandas Series  \n",
    "        all_data.append(series.values)  \n",
    "        all_labels.append(series.name)  \n",
    "  \n",
    "# 将数据转换为numpy数组  \n",
    "data_array = np.array(all_data)  \n",
    "# 将标签转换为编码  \n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "labels_encoded = label_encoder.fit_transform(all_labels)  \n",
    "  \n",
    "# 如果需要one-hot编码  \n",
    "labels_one_hot = to_categorical(labels_encoded)  \n",
    "  \n",
    "# 这里你可能需要reshape data_array 以符合LSTM的输入要求  \n",
    "# LSTM通常要求输入形状为 (samples, time_steps, features)  \n",
    "# 假设每个series的长度相同，或者你可以填充/截断它们以具有相同的长度  \n",
    "time_steps = data_array.shape[1]  # 假设所有series长度相同  \n",
    "data_array = data_array.reshape(-1, time_steps, 1)  # 增加一个维度以匹配LSTM的输入要求\n",
    "\n",
    "# 分割数据集  \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data_array, labels_one_hot, test_size=0.3, random_state=42)  \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5472e40e",
   "metadata": {
    "papermill": {
     "duration": 0.003615,
     "end_time": "2024-07-08T16:26:34.670718",
     "exception": false,
     "start_time": "2024-07-08T16:26:34.667103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4b4326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T16:26:34.680118Z",
     "iopub.status.busy": "2024-07-08T16:26:34.679439Z",
     "iopub.status.idle": "2024-07-08T22:52:46.596045Z",
     "shell.execute_reply": "2024-07-08T22:52:46.594973Z"
    },
    "papermill": {
     "duration": 23171.924175,
     "end_time": "2024-07-08T22:52:46.598645",
     "exception": false,
     "start_time": "2024-07-08T16:26:34.674470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import LSTM, Dense  \n",
    "  \n",
    "model = Sequential()  \n",
    "model.add(LSTM(50, input_shape=(time_steps, 1)))  \n",
    "model.add(Dense(labels_one_hot.shape[1], activation='softmax'))  \n",
    "  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class TimeBasedCheckpoint(Callback):  \n",
    "    def __init__(self, filepath, time_interval_hours=4, verbose=0, save_weights_only=False):  \n",
    "        super(TimeBasedCheckpoint, self).__init__()  \n",
    "        self.filepath = filepath  \n",
    "        self.time_interval_hours = time_interval_hours  \n",
    "        self.verbose = verbose  \n",
    "        self.save_weights_only = save_weights_only  \n",
    "        self.last_save_time = None  \n",
    "  \n",
    "    def on_epoch_begin(self, epoch, logs=None):  \n",
    "        if self.last_save_time is None:  \n",
    "            self.last_save_time = time.time()  \n",
    "            return  \n",
    "  \n",
    "        current_time = time.time()  \n",
    "        elapsed_time = current_time - self.last_save_time  \n",
    "        if elapsed_time / 3600 >= self.time_interval_hours:  \n",
    "            self.save_model(epoch, logs)  \n",
    "            self.last_save_time = current_time  \n",
    "  \n",
    "    def save_model(self, epoch, logs=None):  \n",
    "        filepath = self.filepath.format(epoch=epoch + 1)  # 假设您想将epoch编号包含在文件名中  \n",
    "        if self.save_weights_only:  \n",
    "            self.model.save_weights(filepath, overwrite=True)  \n",
    "        else:  \n",
    "            self.model.save(filepath, overwrite=True)  \n",
    "        if self.verbose > 0:  \n",
    "            print(f'Model saved to {filepath} at epoch {epoch + 1}')  \n",
    "\n",
    "\n",
    "checkpoint = TimeBasedCheckpoint(filepath='/kaggle/working/model.h5', time_interval_hours=4, verbose=1)  \n",
    "history=model.fit(X_train, y_train, epochs=100, batch_size=32 ,callbacks=[checkpoint] ,validation_data=(X_val, y_val))\n",
    "model.save(\"/kaggle/working/EMD_LSTM_model.h5\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7583f049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T22:53:06.090336Z",
     "iopub.status.busy": "2024-07-08T22:53:06.089957Z",
     "iopub.status.idle": "2024-07-08T22:53:06.585239Z",
     "shell.execute_reply": "2024-07-08T22:53:06.584200Z"
    },
    "papermill": {
     "duration": 10.361179,
     "end_time": "2024-07-08T22:53:06.587555",
     "exception": false,
     "start_time": "2024-07-08T22:52:56.226376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# 绘制训练loss和验证loss  \n",
    "plt.plot(history.history['loss'], label='train')  \n",
    "plt.plot(history.history['val_loss'], label='val')  \n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('Model loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.show()  \n",
    "  \n",
    "# 绘制训练accuracy和验证accuracy  \n",
    "plt.plot(history.history['accuracy'], label='train')  \n",
    "plt.plot(history.history['val_accuracy'], label='val')  \n",
    "plt.legend(loc='lower right')  \n",
    "plt.title('Model accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylim(ymin=0, ymax=1)  # 设置y轴的范围为0到1  \n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a8a8377d",
   "metadata": {
    "papermill": {
     "duration": 9.915647,
     "end_time": "2024-07-08T22:53:26.344840",
     "exception": false,
     "start_time": "2024-07-08T22:53:16.429193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e789c032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T22:53:45.757037Z",
     "iopub.status.busy": "2024-07-08T22:53:45.756205Z",
     "iopub.status.idle": "2024-07-08T22:54:23.214019Z",
     "shell.execute_reply": "2024-07-08T22:54:23.212851Z"
    },
    "papermill": {
     "duration": 47.259819,
     "end_time": "2024-07-08T22:54:23.216486",
     "exception": false,
     "start_time": "2024-07-08T22:53:35.956667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.models import load_model  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "  \n",
    "# # 加载模型  \n",
    "# model = load_model(\"/kaggle/input/110spmlstm/keras/110spmlstm/1/model.h5\")  \n",
    "  \n",
    "# 假设X_test和y_test是你的测试数据和真实标签（整数索引）  \n",
    "# 这里需要你已经有了这些变量  \n",
    "  \n",
    "# 预测测试集  \n",
    "y_pred = model.predict(X_test)  \n",
    "# 对于多分类问题，使用argmax获取预测类别索引  \n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  \n",
    "   \n",
    "# 计算混淆矩阵  \n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)  # 确保y_test也是索引形式  \n",
    "  \n",
    "# 获取所有唯一标签的列表，这些标签将对应于整数编码的索引  \n",
    "class_names = label_encoder.classes_  \n",
    "\n",
    "# 绘制混淆矩阵  \n",
    "plt.figure(figsize=(12, 10))  \n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)  \n",
    "plt.ylabel('Actual')  \n",
    "plt.xlabel('Predicted')  \n",
    "plt.title('Confusion Matrix')  \n",
    "plt.show()\n",
    "\n",
    "# 评估模型  \n",
    "loss, accuracy = model.evaluate(X_test, y_test)  \n",
    "print(f'Test loss: {loss:.4f}')  \n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e68d747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T22:54:43.066915Z",
     "iopub.status.busy": "2024-07-08T22:54:43.066134Z",
     "iopub.status.idle": "2024-07-08T22:55:00.820198Z",
     "shell.execute_reply": "2024-07-08T22:55:00.819019Z"
    },
    "papermill": {
     "duration": 27.682806,
     "end_time": "2024-07-08T22:55:00.822426",
     "exception": false,
     "start_time": "2024-07-08T22:54:33.139620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from sklearn.metrics import f1_score, classification_report  \n",
    "import numpy as np  \n",
    "  \n",
    "# 假设 X_test 和 y_test 已经是准备好的测试集数据和标签  \n",
    "  \n",
    "# 使用模型进行预测  \n",
    "y_pred_probs = model.predict(X_test)  # 获取预测的概率  \n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)  # 将概率转换为类别标签  \n",
    "  \n",
    "# 注意：如果你的 y_test 是one-hot编码的，你需要先将其转换为类别索引  \n",
    "y_true_classes = np.argmax(y_test, axis=1)  # 假设 y_test 是one-hot编码的  \n",
    "  \n",
    "# 计算F1分数  \n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')  # 使用加权平均来计算多类别的F1分数  \n",
    "print(f'F1 Score: {f1:.4f}')  \n",
    "  \n",
    "# 计算精确率、召回率和F1分数的详细报告  \n",
    "report = classification_report(y_true_classes, y_pred_classes)  \n",
    "print(report)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5319136,
     "sourceId": 8838704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26284.117031,
   "end_time": "2024-07-08T22:55:13.251638",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-08T15:37:09.134607",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
