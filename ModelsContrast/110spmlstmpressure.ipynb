{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f743e97d",
   "metadata": {
    "papermill": {
     "duration": 0.00333,
     "end_time": "2024-07-09T03:42:57.883072",
     "exception": false,
     "start_time": "2024-07-09T03:42:57.879742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据处理\n",
    "- 原始信号仅仅按照样本熵进行分块，无其他处理；\n",
    "- 标签使用的是独热编码；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7cab23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:42:57.891745Z",
     "iopub.status.busy": "2024-07-09T03:42:57.890780Z",
     "iopub.status.idle": "2024-07-09T03:43:05.807116Z",
     "shell.execute_reply": "2024-07-09T03:43:05.806069Z"
    },
    "papermill": {
     "duration": 7.923242,
     "end_time": "2024-07-09T03:43:05.809417",
     "exception": false,
     "start_time": "2024-07-09T03:42:57.886175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import os  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "    #step1:加载数据集\n",
    "# 设置数据集的路径  \n",
    "data_dir = '../DataFiles/ODS/pressure'   \n",
    "# 创建空的列表来存储所有的DataFrame  \n",
    "X_data0 = []  \n",
    "y_data0 = []\n",
    "# 遍历指定目录下的所有文件  \n",
    "for filename in os.listdir(data_dir):  \n",
    "    if filename.endswith('.csv'):  \n",
    "        # 构建文件的完整路径  \n",
    "        file_path = os.path.join(data_dir, filename)  \n",
    "        # 读取Excel文件  \n",
    "        df = pd.read_csv(file_path)\n",
    "        serie=df.iloc[:, 0]\n",
    "        version_without_extension = filename.rsplit(\".\", 1)[0] \n",
    "        serie.name=version_without_extension\n",
    "        # 将读取的DataFrame添加到列表中  \n",
    "        X_data0.append(serie)\n",
    "        y_data0.append(version_without_extension)\n",
    "\n",
    "    #step2:遍历X_data0中的每个DataFrame，并删除非数字数据  \n",
    "cleaned_data = []  \n",
    "for df in X_data0:  \n",
    "    df_cleaned = df[pd.to_numeric(df, errors='coerce').notnull()]  \n",
    "    cleaned_data.append(df_cleaned)  \n",
    " \n",
    "\n",
    "    #step3:将X_data0中的每个DataFrame的所有元素变为float类型 \n",
    "for i, df in enumerate(cleaned_data):  \n",
    "    X_data0[i] = df.astype(float) \n",
    "\n",
    "# 初始化X_data1来存储结果  \n",
    "X_data1 = []  \n",
    "  \n",
    "# 遍历X_data0中的每个Series  \n",
    "for series in X_data0:  \n",
    "    # 计算步长（由于重叠率为50%，步长为序列长度的一半）  \n",
    "    step_size = 256  # 因为512的一半是256，且我们想要50%的重叠  \n",
    "    # 初始化一个空的list来存储子序列  \n",
    "    subsequences = []  \n",
    "    # 使用range和步长来生成子序列  \n",
    "    for i in range(0, len(series) - 512 + 1, step_size):  \n",
    "        # 确保切片是一维的，并转换为Series（虽然这里切片已经是Series）  \n",
    "        subsequence = series.iloc[i:i+512]  \n",
    "        subsequences.append(subsequence) \n",
    "    X_data1.append(subsequences)  \n",
    "type(X_data1),len(X_data1),len(X_data1[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ed5a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:43:05.818253Z",
     "iopub.status.busy": "2024-07-09T03:43:05.817391Z",
     "iopub.status.idle": "2024-07-09T03:43:20.633268Z",
     "shell.execute_reply": "2024-07-09T03:43:20.631886Z"
    },
    "papermill": {
     "duration": 14.823104,
     "end_time": "2024-07-09T03:43:20.635966",
     "exception": false,
     "start_time": "2024-07-09T03:43:05.812862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from keras.utils import to_categorical\n",
    "import time  \n",
    "from keras.callbacks import Callback  \n",
    "# 假设 X_data1 已经定义好了  \n",
    "all_data = []  \n",
    "all_labels = []  \n",
    "  \n",
    "for sublist in X_data1:  \n",
    "    for series in sublist:  \n",
    "        # 假设每个series是pandas Series  \n",
    "        all_data.append(series.values)  \n",
    "        all_labels.append(series.name)  \n",
    "  \n",
    "# 将数据转换为numpy数组  \n",
    "data_array = np.array(all_data)  \n",
    "# 将标签转换为编码  \n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "labels_encoded = label_encoder.fit_transform(all_labels)  \n",
    "  \n",
    "# 如果需要one-hot编码  \n",
    "labels_one_hot = to_categorical(labels_encoded)  \n",
    "  \n",
    "# 这里你可能需要reshape data_array 以符合LSTM的输入要求  \n",
    "# LSTM通常要求输入形状为 (samples, time_steps, features)  \n",
    "# 假设每个series的长度相同，或者你可以填充/截断它们以具有相同的长度  \n",
    "time_steps = data_array.shape[1]  # 假设所有series长度相同  \n",
    "data_array = data_array.reshape(-1, time_steps, 1)  # 增加一个维度以匹配LSTM的输入要求\n",
    "\n",
    "# 分割数据集  \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data_array, labels_one_hot, test_size=0.3, random_state=42)  \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1f674212",
   "metadata": {
    "papermill": {
     "duration": 0.003221,
     "end_time": "2024-07-09T03:43:20.642795",
     "exception": false,
     "start_time": "2024-07-09T03:43:20.639574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 训练LSTM模型\n",
    "- 直接使用原始信号训练LSTM；\n",
    "- 查看训练过程中的loss和val_loss的变化图；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3314deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:43:20.652031Z",
     "iopub.status.busy": "2024-07-09T03:43:20.650811Z",
     "iopub.status.idle": "2024-07-09T10:07:39.112570Z",
     "shell.execute_reply": "2024-07-09T10:07:39.111210Z"
    },
    "papermill": {
     "duration": 23058.469248,
     "end_time": "2024-07-09T10:07:39.115399",
     "exception": false,
     "start_time": "2024-07-09T03:43:20.646151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import LSTM, Dense  \n",
    "  \n",
    "model = Sequential()  \n",
    "model.add(LSTM(50, input_shape=(time_steps, 1)))  \n",
    "model.add(Dense(labels_one_hot.shape[1], activation='softmax'))  \n",
    "  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class TimeBasedCheckpoint(Callback):  \n",
    "    def __init__(self, filepath, time_interval_hours=4, verbose=0, save_weights_only=False):  \n",
    "        super(TimeBasedCheckpoint, self).__init__()  \n",
    "        self.filepath = filepath  \n",
    "        self.time_interval_hours = time_interval_hours  \n",
    "        self.verbose = verbose  \n",
    "        self.save_weights_only = save_weights_only  \n",
    "        self.last_save_time = None  \n",
    "  \n",
    "    def on_epoch_begin(self, epoch, logs=None):  \n",
    "        if self.last_save_time is None:  \n",
    "            self.last_save_time = time.time()  \n",
    "            return  \n",
    "  \n",
    "        current_time = time.time()  \n",
    "        elapsed_time = current_time - self.last_save_time  \n",
    "        if elapsed_time / 3600 >= self.time_interval_hours:  \n",
    "            self.save_model(epoch, logs)  \n",
    "            self.last_save_time = current_time  \n",
    "  \n",
    "    def save_model(self, epoch, logs=None):  \n",
    "        filepath = self.filepath.format(epoch=epoch + 1)  # 假设您想将epoch编号包含在文件名中  \n",
    "        if self.save_weights_only:  \n",
    "            self.model.save_weights(filepath, overwrite=True)  \n",
    "        else:  \n",
    "            self.model.save(filepath, overwrite=True)  \n",
    "        if self.verbose > 0:  \n",
    "            print(f'Model saved to {filepath} at epoch {epoch + 1}')  \n",
    "\n",
    "\n",
    "checkpoint = TimeBasedCheckpoint(filepath='/kaggle/working/model.h5', time_interval_hours=4, verbose=1)  \n",
    "history=model.fit(X_train, y_train, epochs=100, batch_size=32 ,callbacks=[checkpoint] ,validation_data=(X_val, y_val))\n",
    "model.save(\"/kaggle/working/model.h5\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e990eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T10:07:58.979909Z",
     "iopub.status.busy": "2024-07-09T10:07:58.978782Z",
     "iopub.status.idle": "2024-07-09T10:07:59.548732Z",
     "shell.execute_reply": "2024-07-09T10:07:59.547504Z"
    },
    "papermill": {
     "duration": 10.258126,
     "end_time": "2024-07-09T10:07:59.551132",
     "exception": false,
     "start_time": "2024-07-09T10:07:49.293006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# 绘制训练loss和验证loss  \n",
    "plt.plot(history.history['loss'], label='train')  \n",
    "plt.plot(history.history['val_loss'], label='val')  \n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('Model loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.show()  \n",
    "  \n",
    "# 绘制训练accuracy和验证accuracy  \n",
    "plt.plot(history.history['accuracy'], label='train')  \n",
    "plt.plot(history.history['val_accuracy'], label='val')  \n",
    "plt.legend(loc='lower right')  \n",
    "plt.title('Model accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylim(ymin=0, ymax=1)  # 设置y轴的范围为0到1  \n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "72ae34be",
   "metadata": {
    "papermill": {
     "duration": 9.727606,
     "end_time": "2024-07-09T10:08:19.590739",
     "exception": false,
     "start_time": "2024-07-09T10:08:09.863133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 评估模型效果\n",
    "- 使用测试集获得loss函数为0.4971，准确率为0.8328；(效果不乍地)\n",
    "- 混淆矩阵勉强看着还行；\n",
    "- 精确率（precision）和召回率（recall）\n",
    "- 类别8和11的f1-score小于80%，模型对于这两个的预测效果不好；\n",
    "\n",
    "\n",
    "精确率衡量的是模型预测为正类的样本中，真正为正类的比例；召回率衡量的是所有正类样本中，被模型正确预测为正类的比例。F1分数则是这两个指标的调和平均，因此它同时考虑了模型的精确度和其对所有类别的覆盖率（或灵敏度）。'macro': 简单地对每个类别的F1分数进行未加权平均，赋予每个类别相同的权重，不考虑它们各自的样本数。'weighted': 对每个类别的F1分数进行加权平均，权重是每个类别的支持度（即每个类别的样本数）。这可以看作是对每个类别重要性的一种度量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc10921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T10:08:39.547917Z",
     "iopub.status.busy": "2024-07-09T10:08:39.547433Z",
     "iopub.status.idle": "2024-07-09T10:09:18.039130Z",
     "shell.execute_reply": "2024-07-09T10:09:18.037788Z"
    },
    "papermill": {
     "duration": 48.518723,
     "end_time": "2024-07-09T10:09:18.041623",
     "exception": false,
     "start_time": "2024-07-09T10:08:29.522900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.models import load_model  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "  \n",
    "# # 加载模型  \n",
    "# model = load_model(\"/kaggle/input/110spmlstm/keras/110spmlstm/1/model.h5\")  \n",
    "  \n",
    "# 假设X_test和y_test是你的测试数据和真实标签（整数索引）  \n",
    "# 这里需要你已经有了这些变量  \n",
    "  \n",
    "# 预测测试集  \n",
    "y_pred = model.predict(X_test)  \n",
    "# 对于多分类问题，使用argmax获取预测类别索引  \n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  \n",
    "   \n",
    "# 计算混淆矩阵  \n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)  # 确保y_test也是索引形式  \n",
    "  \n",
    "# 获取所有唯一标签的列表，这些标签将对应于整数编码的索引  \n",
    "class_names = label_encoder.classes_  \n",
    "\n",
    "# 绘制混淆矩阵  \n",
    "plt.figure(figsize=(12, 10))  \n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)  \n",
    "plt.ylabel('Actual')  \n",
    "plt.xlabel('Predicted')  \n",
    "plt.title('Confusion Matrix')  \n",
    "plt.show()\n",
    "\n",
    "# 评估模型  \n",
    "loss, accuracy = model.evaluate(X_test, y_test)  \n",
    "print(f'Test loss: {loss:.4f}')  \n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98cd06fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T10:09:38.171286Z",
     "iopub.status.busy": "2024-07-09T10:09:38.170846Z",
     "iopub.status.idle": "2024-07-09T10:09:56.544775Z",
     "shell.execute_reply": "2024-07-09T10:09:56.543520Z"
    },
    "papermill": {
     "duration": 28.429252,
     "end_time": "2024-07-09T10:09:56.547164",
     "exception": false,
     "start_time": "2024-07-09T10:09:28.117912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "from sklearn.metrics import f1_score, classification_report  \n",
    "import numpy as np  \n",
    "  \n",
    "# 假设 X_test 和 y_test 已经是准备好的测试集数据和标签  \n",
    "  \n",
    "# 使用模型进行预测  \n",
    "y_pred_probs = model.predict(X_test)  # 获取预测的概率  \n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)  # 将概率转换为类别标签  \n",
    "  \n",
    "# 注意：如果你的 y_test 是one-hot编码的，你需要先将其转换为类别索引  \n",
    "y_true_classes = np.argmax(y_test, axis=1)  # 假设 y_test 是one-hot编码的  \n",
    "  \n",
    "# 计算F1分数  \n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')  # 使用加权平均来计算多类别的F1分数  \n",
    "print(f'F1 Score: {f1:.4f}')  \n",
    "  \n",
    "# 计算精确率、召回率和F1分数的详细报告  \n",
    "report = classification_report(y_true_classes, y_pred_classes)  \n",
    "print(report)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5319136,
     "sourceId": 8838704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23234.755911,
   "end_time": "2024-07-09T10:10:09.453231",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-09T03:42:54.697320",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
